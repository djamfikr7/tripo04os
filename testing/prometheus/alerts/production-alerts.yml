groups:
  - name: performance_alerts
    interval: 30s
    rules:
      - alert: HighAPIResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "API P95 response time exceeds 500ms"
          description: "Service {{$labels.service}} P95 response time is {{ $value }}s"

      - alert: CriticalAPIResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.75
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "API P95 response time exceeds 750ms"
          description: "Service {{$labels.service}} P95 response time is {{ $value }}s"

      - alert: HighAPIErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.01
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Error rate exceeds 1%"
          description: "Error rate is {{ $value | humanizePercentage }}"

      - alert: CriticalAPIErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Error rate exceeds 5%"
          description: "Error rate is {{ $value | humanizePercentage }}"

  - name: database_alerts
    interval: 30s
    rules:
      - alert: HighDBQueryTime
        expr: histogram_quantile(0.95, rate(pg_stat_statements_duration_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Database P95 query time exceeds 100ms"

      - alert: CriticalDBQueryTime
        expr: histogram_quantile(0.95, rate(pg_stat_statements_duration_seconds_bucket[5m])) > 0.15
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Database P95 query time exceeds 150ms"

      - alert: HighDBCPUUsage
        expr: rate(pg_stat_statements_calls_total[5m]) > 10000
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Database CPU usage is high"

      - alert: HighDBConnections
        expr: pg_stat_database_numbackends{datname="tripo04os"} > 250
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Database connections exceeding 250"

      - alert: CriticalDBConnections
        expr: pg_stat_database_numbackends{datname="tripo04os"} > 280
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Database connections near limit (300)"

  - name: cache_alerts
    interval: 30s
    rules:
      - alert: LowCacheHitRate
        expr: (rate(redis_cache_hits_total[5m]) / (rate(redis_cache_hits_total[5m]) + rate(redis_cache_misses_total[5m]))) < 0.85
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Cache hit rate below 85%"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"

      - alert: CriticalCacheHitRate
        expr: (rate(redis_cache_hits_total[5m]) / (rate(redis_cache_hits_total[5m]) + rate(redis_cache_misses_total[5m]))) < 0.75
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Cache hit rate below 75%"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"

      - alert: HighRedisMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.8
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Redis memory usage above 80%"

  - name: infrastructure_alerts
    interval: 30s
    rules:
      - alert: HighPodCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) > 0.8
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Pod CPU usage above 80%"

      - alert: HighPodMemoryUsage
        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.85
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Pod memory usage above 85%"

      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Pod {{ $labels.pod }} is crash looping"

      - alert: PodNotReady
        expr: kube_pod_status_ready{condition="true"} == 0
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Pod {{ $labels.pod }} is not ready"

  - name: business_alerts
    interval: 30s
    rules:
      - alert: LowOrderCreationRate
        expr: rate(http_requests_total{endpoint="/api/orders", method="POST"}[15m]) < 10
        for: 10m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "Order creation rate below 10 orders/minute"

      - alert: NoActiveDrivers
        expr: count(drivers_status{status="available"}) == 0
        for: 5m
        labels:
          severity: critical
          team: operations
        annotations:
          summary: "No drivers available in system"

      - alert: HighOrderCancellationRate
        expr: rate(http_requests_total{endpoint=~"/api/orders.*/cancel"}[15m]) / rate(http_requests_total{endpoint="/api/orders"}[15m]) > 0.15
        for: 10m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "Order cancellation rate above 15%"

  - name: sla_alerts
    interval: 1m
    rules:
      - alert: SLABreachAvailability
        expr: (1 - avg_over_time(rate(up{job="api-gateway"}[5m]))) * 100 > 0.1
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "SLA breach: Availability below 99.9%"
          description: "Current availability is {{ $value }}%"

      - alert: SLABreachResponseTime
        expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 1.0
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "SLA breach: P99 response time exceeds 1000ms"
          description: "Current P99 is {{ $value }}s"
