groups:
  - name: critical_alerts
    interval: 30s
    rules:
      # Service Down
      - alert: ServiceDown
        expr: up{job!~"prometheus|alertmanager"} == 0
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Service {{ $labels.service }} is down"
          description: "Service {{ $labels.service }} has been down for more than 5 minutes"

      # High Error Rate
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          /
          sum(rate(http_requests_total[5m])) by (service)
          > 0.01
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High error rate for {{ $labels.service }}"
          description: "Error rate {{ $value | humanizePercentage }} exceeds 1% for {{ $labels.service }}"

      # Slow Response Time
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, http_request_duration_seconds[5m]) > 1
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Slow response time for {{ $labels.endpoint }}"
          description: "95th percentile response time > 1s for {{ $labels.endpoint }}"

      # High Database Connections
      - alert: HighDatabaseConnections
        expr: pg_stat_activity_count > 1000
        for: 5m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "Too many database connections"
          description: "Database connections > 1000 for 5 minutes (current: {{ $value }})"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High memory usage"
          description: "Memory usage > 90% for 5 minutes on {{ $labels.instance }} (current: {{ $value | humanizePercentage }})"

      # Disk Space Low
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
        for: 10m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Low disk space"
          description: "Disk space < 10% on {{ $labels.instance }} (current: {{ $value | humanizePercentage }})"

      # Database Query Slow
      - alert: DatabaseQuerySlow
        expr: |
          histogram_quantile(0.95, pg_stat_statement_duration_seconds[5m]) > 1
        for: 5m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "Slow database queries"
          description: "95th percentile query time > 1s for database {{ $labels.datname }}"

      # Kafka Consumer Lag High
      - alert: KafkaConsumerLagHigh
        expr: kafka_consumergroup_lag > 10000
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High Kafka consumer lag"
          description: "Consumer lag > 10,000 for topic {{ $labels.topic }} group {{ $labels.group }}"

  - name: warning_alerts
    interval: 30s
    rules:
      # Elevated Error Rate
      - alert: ElevatedErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"4.."}[15m])) by (service)
          /
          sum(rate(http_requests_total[15m])) by (service)
          > 0.005
        for: 15m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Elevated error rate for {{ $labels.service }}"
          description: "Error rate > 0.5% for {{ $labels.service }} (current: {{ $value | humanizePercentage }})"

      # High Response Time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, http_request_duration_seconds[15m]) > 0.5
        for: 15m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High response time for {{ $labels.endpoint }}"
          description: "95th percentile response time > 500ms for {{ $labels.endpoint }} (current: {{ $value }}s)"

      # Database Connection Pool Exhaustion
      - alert: DatabaseConnectionPoolExhaustion
        expr: |
          (pg_stat_activity_count / pg_settings_max_connections) > 0.8
        for: 15m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "Active connections > 80% of max (current: {{ $value | humanizePercentage }})"

      # CPU Usage High
      - alert: CPUUsageHigh
        expr: |
          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High CPU usage"
          description: "CPU usage > 80% for 10 minutes on {{ $labels.instance }} (current: {{ $value }}%)"

      # Redis Memory High
      - alert: RedisMemoryHigh
        expr: |
          (redis_memory_used_bytes / redis_memory_max_bytes) > 0.8
        for: 15m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Redis memory usage high"
          description: "Redis memory usage > 80% on {{ $labels.instance }} (current: {{ $value | humanizePercentage }})"

      # API Request Rate Low
      - alert: APIRequestRateLow
        expr: |
          rate(http_requests_total[5m]) < 10
        for: 15m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "Low API request rate"
          description: "Request rate < 10 req/s for {{ $labels.service }} (current: {{ $value }} req/s)"

  - name: info_alerts
    interval: 30s
    rules:
      # Database Connection Count
      - alert: DatabaseConnectionCount
        expr: pg_stat_activity_count > 0
        for: 1h
        labels:
          severity: info
          team: database
        annotations:
          summary: "Database connection count"
          description: "Number of active database connections: {{ $value }}"

      # Kafka Topic Messages
      - alert: KafkaTopicMessages
        expr: kafka_topic_partition_current_offset > 0
        for: 1h
        labels:
          severity: info
          team: platform
        annotations:
          summary: "Kafka topic messages"
          description: "Total messages in topic {{ $labels.topic }}: {{ $value }}"

      # Service Deployment
      - alert: ServiceDeployment
        expr: up{job=~"identity-service|order-service|trip-service"} == 1
        for: 1h
        labels:
          severity: info
          team: platform
        annotations:
          summary: "Service deployed and running"
          description: "Service {{ $labels.service }} is running on {{ $labels.instance }}"

      # Active Users
      - alert: ActiveUsers
        expr: sum by (service) (rate(http_requests_total[5m])) > 0
        for: 1h
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Active users detected"
          description: "Current request rate for {{ $labels.service }}: {{ $value }} req/s"

      # Orders Created
      - alert: OrdersCreated
        expr: rate(orders_total{status="created"}[5m]) > 0
        for: 1h
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Orders being created"
          description: "Order creation rate: {{ $value }} orders/sec"

      # Trips Active
      - alert: TripsActive
        expr: trips_total{status="in_progress"} > 0
        for: 1h
        labels:
          severity: info
          team: analytics
        annotations:
          summary: "Active trips in progress"
          description: "Number of active trips: {{ $value }}"

  - name: sla_alerts
    interval: 30s
    rules:
      # SLA Violation - Response Time
      - alert: SLAViolationResponseTime
        expr: |
          histogram_quantile(0.99, http_request_duration_seconds[5m]) > 1
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "SLA violation - Response time"
          description: "99th percentile response time > 1s for {{ $labels.endpoint }} (SLA target: < 1s)"

      # SLA Violation - Error Rate
      - alert: SLAViolationErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
          /
          sum(rate(http_requests_total[5m])) by (service)
          > 0.01
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "SLA violation - Error rate"
          description: "Error rate > 1% for {{ $labels.service }} (SLA target: < 1%)"

      # SLA Violation - Uptime
      - alert: SLAViolationUptime
        expr: |
          avg_over_time(up{job!~"prometheus|alertmanager"}[1h]) < 0.99
        for: 1h
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "SLA violation - Uptime"
          description: "Service uptime < 99% for {{ $labels.service }} (SLA target: > 99.9%)"

  - name: security_alerts
    interval: 30s
    rules:
      # Authentication Failures High
      - alert: AuthFailuresHigh
        expr: |
          rate(auth_login_total{success="false"}[5m]) / rate(auth_login_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High authentication failure rate"
          description: "Authentication failure rate > 10% for {{ $labels.instance }} (potential brute force attack)"

      # Unauthorized Access Attempts
      - alert: UnauthorizedAccessAttempts
        expr: |
          sum(rate(http_requests_total{status="401"}[5m])) by (service) > 10
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "Unauthorized access attempts"
          description: "High rate of 401 errors for {{ $labels.service }} (current: {{ $value }} req/s)"

      # Rate Limit Exceeded
      - alert: RateLimitExceeded
        expr: |
          sum(rate(http_requests_total{status="429"}[5m])) by (service) > 5
        for: 5m
        labels:
          severity: info
          team: security
        annotations:
          summary: "Rate limit exceeded"
          description: "High rate of 429 errors for {{ $labels.service }} (current: {{ $value }} req/s)"

      # Suspicious Activity
      - alert: SuspiciousActivity
        expr: |
          sum(increase(auth_login_total{success="false"}[10m])) by (ip) > 20
        for: 10m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "Suspicious activity detected"
          description: "More than 20 failed login attempts from IP {{ $labels.ip }} in 10 minutes"
